{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 86946,
          "databundleVersionId": 10131489,
          "sourceType": "competition"
        },
        {
          "sourceId": 10135513,
          "sourceType": "datasetVersion",
          "datasetId": 6255265
        },
        {
          "sourceId": 10140290,
          "sourceType": "datasetVersion",
          "datasetId": 6256972
        },
        {
          "sourceId": 75103,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 63082,
          "modelId": 86587
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "papermill": {
      "default_parameters": {},
      "duration": 148.347272,
      "end_time": "2024-07-10T01:15:35.655682",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-07-10T01:13:07.30841",
      "version": "2.5.0"
    },
    "colab": {
      "name": "Inference",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jxm020202/Multilingual-Chatbot-WDSM-CUP/blob/main/Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "jabjeIPKxs6A"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "wsdm_cup_multilingual_chatbot_arena_path = kagglehub.competition_download('wsdm-cup-multilingual-chatbot-arena')\n",
        "jxm222_checkpoint_8th_path = kagglehub.dataset_download('jxm222/checkpoint-8th')\n",
        "jxm222_wheels_path = kagglehub.dataset_download('jxm222/wheels')\n",
        "emiz6413_gemma_2_transformers_gemma_2_9b_it_4bit_1_path = kagglehub.model_download('emiz6413/gemma-2/Transformers/gemma-2-9b-it-4bit/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "CZQwVz8cxs6A"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "_uuid": "b5f4384b-02cf-4161-92fd-c3cc73c4ac2f",
        "_cell_guid": "7468d1db-7ecf-4599-b350-2e9708f63fbd",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "MXviWRukxs6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft accelerate transformers bitsandbytes\\\n",
        "    -U --no-index --find-links /kaggle/input/wheels"
      ],
      "metadata": {
        "_uuid": "54b2481b-78a1-4312-bf53-8aff98e89101",
        "_cell_guid": "a40dadfe-db58-4719-956d-5a8453bdfeea",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T02:45:49.694811Z",
          "iopub.execute_input": "2024-12-09T02:45:49.695049Z",
          "iopub.status.idle": "2024-12-09T02:45:57.962857Z",
          "shell.execute_reply.started": "2024-12-09T02:45:49.695023Z",
          "shell.execute_reply": "2024-12-09T02:45:57.961486Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "3UY9XbpWxs6B"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from dataclasses import dataclass\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "import torch\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
        "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
        "from peft import PeftModel"
      ],
      "metadata": {
        "_uuid": "0603880f-f17a-4ccf-862b-c4c9c027deb6",
        "_cell_guid": "329263d0-fcba-4927-9bac-eb16ee2f5c12",
        "trusted": true,
        "papermill": {
          "duration": 19.200405,
          "end_time": "2024-07-10T01:14:00.90474",
          "exception": false,
          "start_time": "2024-07-10T01:13:41.704335",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T02:45:57.964185Z",
          "iopub.execute_input": "2024-12-09T02:45:57.964631Z",
          "iopub.status.idle": "2024-12-09T02:46:04.278693Z",
          "shell.execute_reply.started": "2024-12-09T02:45:57.964582Z",
          "shell.execute_reply": "2024-12-09T02:46:04.277903Z"
        },
        "id": "GrFG5PB8xs6C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "assert torch.cuda.device_count() == 2"
      ],
      "metadata": {
        "_uuid": "50026836-746b-430e-b7c8-a7357873b07e",
        "_cell_guid": "deb4e4b1-f792-446f-9e1d-27c126739397",
        "trusted": true,
        "papermill": {
          "duration": 0.047799,
          "end_time": "2024-07-10T01:14:00.965921",
          "exception": false,
          "start_time": "2024-07-10T01:14:00.918122",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:04.279656Z",
          "iopub.execute_input": "2024-12-09T02:46:04.280091Z",
          "iopub.status.idle": "2024-12-09T02:46:04.31862Z",
          "shell.execute_reply.started": "2024-12-09T02:46:04.280064Z",
          "shell.execute_reply": "2024-12-09T02:46:04.317978Z"
        },
        "id": "OW7xts4jxs6C"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "_uuid": "576b0719-760e-4fbe-9bc5-bae2663163f9",
        "_cell_guid": "a87c87f7-1cdc-40da-8c35-3e14299fc062",
        "trusted": true,
        "collapsed": false,
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "j3r99G5hxs6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'\n",
        "    lora_dir = '/kaggle/input/checkpoint-8th'\n",
        "    max_length = 512*3\n",
        "    batch_size = 4\n",
        "    device = torch.device(\"cuda\")\n",
        "    tta = True\n",
        "    spread_max_length = False  # whether to apply max_length//3 on each input or max_length on the concatenated input\n",
        "\n",
        "cfg = Config()"
      ],
      "metadata": {
        "_uuid": "1ca3df1d-1c08-4d0c-9c8f-995506ed3a06",
        "_cell_guid": "16122445-6e66-40cf-857f-944fdd000fc9",
        "trusted": true,
        "papermill": {
          "duration": 0.021338,
          "end_time": "2024-07-10T01:14:01.000606",
          "exception": false,
          "start_time": "2024-07-10T01:14:00.979268",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:04.320327Z",
          "iopub.execute_input": "2024-12-09T02:46:04.320713Z",
          "iopub.status.idle": "2024-12-09T02:46:04.325665Z",
          "shell.execute_reply.started": "2024-12-09T02:46:04.320678Z",
          "shell.execute_reply": "2024-12-09T02:46:04.324722Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "IV3GPT0Pxs6D"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load & pre-process Data"
      ],
      "metadata": {
        "_uuid": "5e46bb68-8cca-45ff-8410-bef97d6e9ac6",
        "_cell_guid": "b29483d1-89f2-4356-8d0d-35bb01afdda7",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.012663,
          "end_time": "2024-07-10T01:14:01.026248",
          "exception": false,
          "start_time": "2024-07-10T01:14:01.013585",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "LCzEkv3xxs6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')"
      ],
      "metadata": {
        "_uuid": "d2a46c42-c4b9-4215-9920-041f635cafaa",
        "_cell_guid": "c021bd34-3286-4f0a-9b27-7d5540986f25",
        "trusted": true,
        "papermill": {
          "duration": 0.02967,
          "end_time": "2024-07-10T01:14:01.06946",
          "exception": false,
          "start_time": "2024-07-10T01:14:01.03979",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:04.326583Z",
          "iopub.execute_input": "2024-12-09T02:46:04.326859Z",
          "iopub.status.idle": "2024-12-09T02:46:04.391008Z",
          "shell.execute_reply.started": "2024-12-09T02:46:04.326835Z",
          "shell.execute_reply": "2024-12-09T02:46:04.390407Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "m338AZyAxs6E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "_uuid": "2445a606-21b4-4772-bc03-4526d0b734ab",
        "_cell_guid": "b29f45d9-26a4-4304-94b8-37d52be1eb75",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:04.392152Z",
          "iopub.execute_input": "2024-12-09T02:46:04.392516Z",
          "iopub.status.idle": "2024-12-09T02:46:04.404547Z",
          "shell.execute_reply.started": "2024-12-09T02:46:04.39248Z",
          "shell.execute_reply": "2024-12-09T02:46:04.403735Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "GZzoAeTtxs6E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(text: str) -> str:\n",
        "    return text.replace(\"null\", \"\").strip()\n",
        "\n",
        "\n",
        "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)\n",
        "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)\n",
        "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)"
      ],
      "metadata": {
        "_uuid": "d5521dc8-d70e-4d9e-af99-2d7f04b3296d",
        "_cell_guid": "49e6dbce-35ec-4c88-aba8-367e757832f3",
        "trusted": true,
        "papermill": {
          "duration": 0.040127,
          "end_time": "2024-07-10T01:14:01.12241",
          "exception": false,
          "start_time": "2024-07-10T01:14:01.082283",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:04.405577Z",
          "iopub.execute_input": "2024-12-09T02:46:04.405818Z",
          "iopub.status.idle": "2024-12-09T02:46:04.41164Z",
          "shell.execute_reply.started": "2024-12-09T02:46:04.405795Z",
          "shell.execute_reply": "2024-12-09T02:46:04.41081Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "56uc7AKlxs6E"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize"
      ],
      "metadata": {
        "_uuid": "48a398dd-103d-48fb-abe0-e98247deabf2",
        "_cell_guid": "0c23aab4-93f3-4a60-bcd9-1c196b779d95",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.012864,
          "end_time": "2024-07-10T01:14:01.148412",
          "exception": false,
          "start_time": "2024-07-10T01:14:01.135548",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "maOiAhA8xs6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(\n",
        "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
        "):\n",
        "    # TODO: change prompt\n",
        "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
        "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n",
        "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n",
        "    if spread_max_length:\n",
        "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
        "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
        "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
        "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
        "        attention_mask = [[1]* len(i) for i in input_ids]\n",
        "    else:\n",
        "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
        "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
        "        input_ids = tokenized.input_ids\n",
        "        attention_mask = tokenized.attention_mask\n",
        "    return input_ids, attention_mask"
      ],
      "metadata": {
        "_uuid": "bacedcf4-5780-43a1-ae56-0760af7bda49",
        "_cell_guid": "f1287da4-a376-4616-88d6-603b7206baa6",
        "trusted": true,
        "papermill": {
          "duration": 0.030237,
          "end_time": "2024-07-10T01:14:01.194318",
          "exception": false,
          "start_time": "2024-07-10T01:14:01.164081",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:04.412795Z",
          "iopub.execute_input": "2024-12-09T02:46:04.413025Z",
          "iopub.status.idle": "2024-12-09T02:46:04.424025Z",
          "shell.execute_reply.started": "2024-12-09T02:46:04.413003Z",
          "shell.execute_reply": "2024-12-09T02:46:04.423346Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "9QdIlgxIxs6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
        "tokenizer.add_eos_token = True\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "data = pd.DataFrame()\n",
        "data[\"id\"] = test[\"id\"]\n",
        "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
        "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
        "\n",
        "aug_data = pd.DataFrame()\n",
        "aug_data[\"id\"] = test[\"id\"]\n",
        "# swap response_a & response_b\n",
        "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
        "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
      ],
      "metadata": {
        "_uuid": "9aea8749-b8af-4331-90cd-074ea596a7d6",
        "_cell_guid": "27a154b1-fbe8-438a-bd76-51f9e94a31d5",
        "trusted": true,
        "papermill": {
          "duration": 1.169844,
          "end_time": "2024-07-10T01:14:02.377579",
          "exception": false,
          "start_time": "2024-07-10T01:14:01.207735",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:04.424847Z",
          "iopub.execute_input": "2024-12-09T02:46:04.42507Z",
          "iopub.status.idle": "2024-12-09T02:46:05.488455Z",
          "shell.execute_reply.started": "2024-12-09T02:46:04.425047Z",
          "shell.execute_reply": "2024-12-09T02:46:05.487581Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "aqLSgj0Sxs6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "_uuid": "6dd1c6f6-60ce-4b0c-adb0-a6b1fe6f9ba6",
        "_cell_guid": "f867cb70-c267-482b-8fe5-edfee4eb39d1",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.013054,
          "end_time": "2024-07-10T01:14:02.480304",
          "exception": false,
          "start_time": "2024-07-10T01:14:02.46725",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "HLvu0xz_xs6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model on GPU 0\n",
        "device_0 = torch.device('cuda:0')\n",
        "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
        "    cfg.gemma_dir,\n",
        "    device_map=device_0,\n",
        "    use_cache=False,\n",
        ")\n",
        "\n",
        "# Load base model on GPU 1\n",
        "device_1 = torch.device('cuda:1')\n",
        "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
        "    cfg.gemma_dir,\n",
        "    device_map=device_1,\n",
        "    use_cache=False,\n",
        ")"
      ],
      "metadata": {
        "_uuid": "98897529-40e2-4a06-ad4e-1032c1b491b3",
        "_cell_guid": "9a1e31e0-cd25-4ef4-915e-03052ab31614",
        "trusted": true,
        "papermill": {
          "duration": 83.919146,
          "end_time": "2024-07-10T01:15:26.412583",
          "exception": false,
          "start_time": "2024-07-10T01:14:02.493437",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:05.489434Z",
          "iopub.execute_input": "2024-12-09T02:46:05.489715Z",
          "iopub.status.idle": "2024-12-09T02:46:12.457011Z",
          "shell.execute_reply.started": "2024-12-09T02:46:05.489689Z",
          "shell.execute_reply": "2024-12-09T02:46:12.456197Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "xOgLNOUnxs6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load LoRA adapter"
      ],
      "metadata": {
        "_uuid": "d78de316-d1d1-4de2-8bf3-58daab8480e3",
        "_cell_guid": "ceb7d05f-2f26-417f-854d-df84bbeb1e26",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.013639,
          "end_time": "2024-07-10T01:15:26.440571",
          "exception": false,
          "start_time": "2024-07-10T01:15:26.426932",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "KCCo_PK7xs6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)\n",
        "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)"
      ],
      "metadata": {
        "_uuid": "7eeb174d-d63a-4609-b605-063ed17ce97f",
        "_cell_guid": "5d362f6d-cc6e-4342-9222-a6cb4da8669b",
        "trusted": true,
        "papermill": {
          "duration": 1.265087,
          "end_time": "2024-07-10T01:15:27.719297",
          "exception": false,
          "start_time": "2024-07-10T01:15:26.45421",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:12.458157Z",
          "iopub.execute_input": "2024-12-09T02:46:12.458557Z",
          "iopub.status.idle": "2024-12-09T02:46:13.157101Z",
          "shell.execute_reply.started": "2024-12-09T02:46:12.458518Z",
          "shell.execute_reply": "2024-12-09T02:46:13.156289Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "W0DMJA4Axs6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "_uuid": "6c2e8518-0c94-4afa-bee3-9271a7f83c92",
        "_cell_guid": "67e27424-80ef-4fb0-8488-6de865095340",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.013989,
          "end_time": "2024-07-10T01:15:27.797512",
          "exception": false,
          "start_time": "2024-07-10T01:15:27.783523",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "eYAZhwOExs6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "@torch.cuda.amp.autocast()\n",
        "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
        "    # Initialize lists to store probabilities\n",
        "    a_win, b_win = [], []\n",
        "\n",
        "    for start_idx in range(0, len(df), batch_size):\n",
        "        # Select the current batch\n",
        "        tmp = df.iloc[start_idx:start_idx + batch_size]\n",
        "        inputs = pad_without_fast_tokenizer_warning(\n",
        "            tokenizer,\n",
        "            {\n",
        "                \"input_ids\": tmp[\"input_ids\"].to_list(),\n",
        "                \"attention_mask\": tmp[\"attention_mask\"].to_list(),\n",
        "            },\n",
        "            padding=\"longest\",\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        # Perform inference\n",
        "        outputs = model(**inputs.to(device))\n",
        "        proba = outputs.logits.softmax(-1).cpu()\n",
        "\n",
        "        # Append probabilities\n",
        "        a_win.extend(proba[:, 0].tolist())\n",
        "        b_win.extend(proba[:, 1].tolist())\n",
        "\n",
        "    # Create a copy of the dataframe and add the results\n",
        "    result_df = df.copy()\n",
        "    result_df[\"winner_model_a\"] = a_win\n",
        "    result_df[\"winner_model_b\"] = b_win\n",
        "\n",
        "    return result_df"
      ],
      "metadata": {
        "_uuid": "66e159de-e08c-4488-a3a8-f73636bfd8fd",
        "_cell_guid": "b862fba2-0426-48bd-bfb6-1768daa3c0fc",
        "trusted": true,
        "papermill": {
          "duration": 0.026726,
          "end_time": "2024-07-10T01:15:27.838497",
          "exception": false,
          "start_time": "2024-07-10T01:15:27.811771",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:31.899201Z",
          "iopub.execute_input": "2024-12-09T02:46:31.899964Z",
          "iopub.status.idle": "2024-12-09T02:46:31.907128Z",
          "shell.execute_reply.started": "2024-12-09T02:46:31.899929Z",
          "shell.execute_reply": "2024-12-09T02:46:31.906264Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "NTBPNMy4xs6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "st = time.time()\n",
        "\n",
        "# sort by input length to fully leverage dynaminc padding\n",
        "data = data.sort_values(\"length\", ascending=False)\n",
        "# the total #tokens in sub_1 and sub_2 should be more or less the same\n",
        "sub_1 = data.iloc[0::2].copy()\n",
        "sub_2 = data.iloc[1::2].copy()\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
        "\n",
        "result_df = pd.concat(list(results), axis=0)\n",
        "proba = result_df[[\"winner_model_a\", \"winner_model_b\"]].values\n",
        "\n",
        "print(f\"elapsed time: {time.time() - st}\")"
      ],
      "metadata": {
        "_uuid": "a5f7e244-adc5-44be-9f56-5347288e3b66",
        "_cell_guid": "6752e7fb-f48b-4920-996e-664d07a43b45",
        "trusted": true,
        "papermill": {
          "duration": 4.598663,
          "end_time": "2024-07-10T01:15:32.45234",
          "exception": false,
          "start_time": "2024-07-10T01:15:27.853677",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:35.179111Z",
          "iopub.execute_input": "2024-12-09T02:46:35.179508Z",
          "iopub.status.idle": "2024-12-09T02:46:39.990464Z",
          "shell.execute_reply.started": "2024-12-09T02:46:35.179475Z",
          "shell.execute_reply": "2024-12-09T02:46:39.989587Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "F2Y0TQLuxs6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "st = time.time()\n",
        "\n",
        "if cfg.tta:\n",
        "    # Sort augmented data by length for efficient dynamic padding\n",
        "    aug_data = aug_data.sort_values(\"length\", ascending=False)\n",
        "\n",
        "    # Split into two subsets for parallel processing\n",
        "    sub_1, sub_2 = aug_data.iloc[0::2], aug_data.iloc[1::2]\n",
        "\n",
        "    # Perform inference with TTA using ThreadPoolExecutor\n",
        "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        results = executor.map(inference, [sub_1, sub_2], [model_0, model_1], [device_0, device_1])\n",
        "\n",
        "    tta_result_df = pd.concat(results, axis=0)\n",
        "    tta_proba = tta_result_df[[\"winner_model_a\", \"winner_model_b\"]].values\n",
        "\n",
        "    # Combine original and TTA probabilities by averaging\n",
        "    proba = (proba + tta_proba) / 2"
      ],
      "metadata": {
        "_uuid": "a4027bbb-3403-43e8-88ff-93f1fad07fab",
        "_cell_guid": "c1e8c4d3-d3fb-436a-b7b2-321f8ea61632",
        "trusted": true,
        "papermill": {
          "duration": 0.024559,
          "end_time": "2024-07-10T01:15:32.491283",
          "exception": false,
          "start_time": "2024-07-10T01:15:32.466724",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:41.906912Z",
          "iopub.execute_input": "2024-12-09T02:46:41.907596Z",
          "iopub.status.idle": "2024-12-09T02:46:46.745554Z",
          "shell.execute_reply.started": "2024-12-09T02:46:41.907561Z",
          "shell.execute_reply": "2024-12-09T02:46:46.744509Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Jtg00sNwxs6F"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def determine_winner(row):\n",
        "    return \"model_a\" if row[\"winner_model_a\"] > row[\"winner_model_b\"] else \"model_b\"\n",
        "\n",
        "\n",
        "# Store probabilities in the result dataframe\n",
        "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]\n",
        "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]\n",
        "\n",
        "# Determine winners\n",
        "result_df[\"winner\"] = result_df.apply(determine_winner, axis=1)\n",
        "\n",
        "# Save submission\n",
        "submission_df = result_df[[\"id\", \"winner\"]]\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "display(submission_df)"
      ],
      "metadata": {
        "_uuid": "dc8ea919-1817-4452-accf-b7ad3d215c6c",
        "_cell_guid": "8ab4030e-a75c-48bd-83d7-80164077adb1",
        "trusted": true,
        "papermill": {
          "duration": 0.034664,
          "end_time": "2024-07-10T01:15:32.539974",
          "exception": false,
          "start_time": "2024-07-10T01:15:32.50531",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-12-09T02:46:49.620322Z",
          "iopub.execute_input": "2024-12-09T02:46:49.620663Z",
          "iopub.status.idle": "2024-12-09T02:46:49.632753Z",
          "shell.execute_reply.started": "2024-12-09T02:46:49.620633Z",
          "shell.execute_reply": "2024-12-09T02:46:49.63197Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "-pgHvctLxs6G"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}