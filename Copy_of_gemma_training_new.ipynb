{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 86946,
          "databundleVersionId": 10131489,
          "sourceType": "competition"
        },
        {
          "sourceId": 8926343,
          "sourceType": "datasetVersion",
          "datasetId": 5369301
        },
        {
          "sourceId": 10135513,
          "sourceType": "datasetVersion",
          "datasetId": 6255265
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a612a945c482487d9052cdf7703af8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b61e96d8a544ea97b4ccd50eaf1cb3",
              "IPY_MODEL_3dd25d8aa94a42e9bce729565b69586d",
              "IPY_MODEL_25a8ac93fcc84463a701094802de2421"
            ],
            "layout": "IPY_MODEL_1b8ab69b6a9447599432ffdd041f9ece"
          }
        },
        "b3b61e96d8a544ea97b4ccd50eaf1cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfbbb379c5104807994de4d039de0b7a",
            "placeholder": "​",
            "style": "IPY_MODEL_ca6c834d83b64c23a0cd038e6ccba46d",
            "value": "Map: 100%"
          }
        },
        "3dd25d8aa94a42e9bce729565b69586d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a400f11c9f4f508b7e0e3407d110ee",
            "max": 48439,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_535e83ed058f493b9090792e174e9cdc",
            "value": 48439
          }
        },
        "25a8ac93fcc84463a701094802de2421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e153a3b809f545ccb31ab0670a24b5b8",
            "placeholder": "​",
            "style": "IPY_MODEL_f9316725a85644faa47259a3ae4ab03d",
            "value": " 48439/48439 [02:44&lt;00:00, 318.43 examples/s]"
          }
        },
        "1b8ab69b6a9447599432ffdd041f9ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfbbb379c5104807994de4d039de0b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca6c834d83b64c23a0cd038e6ccba46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a400f11c9f4f508b7e0e3407d110ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "535e83ed058f493b9090792e174e9cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e153a3b809f545ccb31ab0670a24b5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9316725a85644faa47259a3ae4ab03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jxm020202/Multilingual-Chatbot-WDSM-CUP/blob/main/Copy_of_gemma_training_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "'''# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n",
        "'''"
      ],
      "metadata": {
        "id": "brFIb_ndmX1L",
        "outputId": "9fa854f6-a447-4563-a150-83911c4abdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\\nimport kagglehub\\nkagglehub.login()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "In4BRAaRLpnC",
        "outputId": "4273ae7a-d50c-4a93-80bc-a6ef05478c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "wsdm_cup_multilingual_chatbot_arena_path = kagglehub.competition_download('wsdm-cup-multilingual-chatbot-arena')\n",
        "emiz6413_73zap2gx_path = kagglehub.dataset_download('emiz6413/73zap2gx')\n",
        "jxm222_checkpoint_8th_path = kagglehub.dataset_download('jxm222/checkpoint-8th')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "o0Vi4mhJmX1M",
        "outputId": "1b17a014-0138-43ca-d154-04ac78984c08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install -U transformers>=4.42.3 bitsandbytes accelerate peft datasets scikit-learn"
      ],
      "metadata": {
        "_uuid": "e507c717-de37-43b8-99d0-9c07fc6efeb8",
        "_cell_guid": "711bf878-447e-4323-b9c7-269e6f026405",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T07:55:32.504357Z",
          "iopub.execute_input": "2024-12-08T07:55:32.505001Z",
          "iopub.status.idle": "2024-12-08T07:55:32.509152Z",
          "shell.execute_reply.started": "2024-12-08T07:55:32.504958Z",
          "shell.execute_reply": "2024-12-08T07:55:32.508346Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "d1amNiKCmX1N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "from dataclasses import dataclass\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    BitsAndBytesConfig,\n",
        "    Gemma2ForSequenceClassification,\n",
        "    GemmaTokenizerFast,\n",
        "    Gemma2Config,\n",
        "    PreTrainedTokenizerBase,\n",
        "    EvalPrediction,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding,\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
        "from sklearn.metrics import log_loss, accuracy_score"
      ],
      "metadata": {
        "_uuid": "05133a1b-11a2-408c-9a51-d0f0764427ce",
        "_cell_guid": "16f7b74f-340d-4a96-b645-5a7756c58216",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T07:55:32.510623Z",
          "iopub.execute_input": "2024-12-08T07:55:32.510929Z",
          "iopub.status.idle": "2024-12-08T07:55:51.131382Z",
          "shell.execute_reply.started": "2024-12-08T07:55:32.510891Z",
          "shell.execute_reply": "2024-12-08T07:55:51.130645Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "LQW0Q2b8mX1N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    output_dir: str = \"/content/drive/MyDrive/wdsm-checkpoints\"\n",
        "\n",
        "    checkpoint: str = \"unsloth/gemma-2-9b-it-bnb-4bit\"  # 4-bit quantized gemma-2-9b-instruct\n",
        "    train_parquet: str = wsdm_cup_multilingual_chatbot_arena_path +\"/train.parquet\"\n",
        "    max_length: int = 820\n",
        "    n_splits: int = 5\n",
        "    fold_idx: int = 0\n",
        "    optim_type: str = \"adamw_8bit\"\n",
        "    per_device_train_batch_size: int = 4\n",
        "    per_device_eval_batch_size: int = 8\n",
        "    n_epochs: int = 1\n",
        "    freeze_layers: int = 16  # there're 42 layers in total, we don't add adapters to the first 16 layers\n",
        "    lr: float = 3e-4\n",
        "    lora_r: int = 64\n",
        "    lora_alpha: float = lora_r * 2\n",
        "    lora_dropout: float = 0.05\n",
        "    lora_bias: str = \"none\"\n",
        "    lora_dir = \"/content/checkpoint-9\"\n",
        "\n",
        "config = Config()"
      ],
      "metadata": {
        "_uuid": "355e2861-16d5-43e2-ac69-1116bbbdb017",
        "_cell_guid": "9169053e-d012-4aca-a88e-8531c5b93f8d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T07:55:51.132383Z",
          "iopub.execute_input": "2024-12-08T07:55:51.132899Z",
          "iopub.status.idle": "2024-12-08T07:55:51.139386Z",
          "shell.execute_reply.started": "2024-12-08T07:55:51.132871Z",
          "shell.execute_reply": "2024-12-08T07:55:51.13833Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "MiY6HB6lmX1N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output\",\n",
        "    overwrite_output_dir=True,\n",
        "\n",
        "    num_train_epochs=config.n_epochs,\n",
        "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=2,\n",
        "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
        "    logging_steps=1,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=50,\n",
        "    optim=config.optim_type,\n",
        "    fp16=True,\n",
        "    learning_rate=config.lr,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "_uuid": "ebf89fd4-0734-4650-87e0-d5b1f8de34aa",
        "_cell_guid": "30833a44-dcea-4617-a061-b13aede877d6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T07:55:51.140507Z",
          "iopub.execute_input": "2024-12-08T07:55:51.140834Z",
          "iopub.status.idle": "2024-12-08T07:55:51.280706Z",
          "shell.execute_reply.started": "2024-12-08T07:55:51.140795Z",
          "shell.execute_reply": "2024-12-08T07:55:51.279668Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "VEy3LjQSmX1N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=config.lora_r,\n",
        "    lora_alpha=config.lora_alpha,\n",
        "    # only target self-attention\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
        "    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n",
        "    lora_dropout=config.lora_dropout,\n",
        "    bias=config.lora_bias,\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        ")"
      ],
      "metadata": {
        "_uuid": "6ba4ac10-6e2d-48a8-975d-bc5462ea8ca2",
        "_cell_guid": "ec8ed692-e9f0-479a-8ddc-72cc1b21d811",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T07:55:51.281843Z",
          "iopub.execute_input": "2024-12-08T07:55:51.282098Z",
          "iopub.status.idle": "2024-12-08T07:55:51.286987Z",
          "shell.execute_reply.started": "2024-12-08T07:55:51.282074Z",
          "shell.execute_reply": "2024-12-08T07:55:51.286103Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "oIo69Rs6mX1N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GemmaTokenizerFast.from_pretrained(config.checkpoint)\n",
        "tokenizer.add_eos_token = True  # We'll add <eos> at the end\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "_uuid": "a88d83a7-a274-45e0-8a0d-614a943336e7",
        "_cell_guid": "bc206134-c10e-46c7-b70d-d9717d1f1342",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T07:55:51.288195Z",
          "iopub.execute_input": "2024-12-08T07:55:51.28889Z",
          "iopub.status.idle": "2024-12-08T07:55:53.851258Z",
          "shell.execute_reply.started": "2024-12-08T07:55:51.288859Z",
          "shell.execute_reply": "2024-12-08T07:55:53.850505Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "_YfjHydxmX1N",
        "outputId": "4c43657d-93db-489d-f4d0-1bf9fe531598",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Gemma2ForSequenceClassification.from_pretrained(\n",
        "    config.checkpoint,\n",
        "    num_labels=2,  # directly load 2 classes from start\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "from peft import PeftModel\n",
        "\n",
        "model = PeftModel.from_pretrained(model, config.lora_dir, device_map=\"auto\")\n",
        "\n",
        "\n",
        "# No manual classifier replacement needed now.\n"
      ],
      "metadata": {
        "_uuid": "a473509b-e375-491d-b51b-a5bfd20c6112",
        "_cell_guid": "d114e973-f1c8-468c-b111-550b3f6a8486",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-08T07:55:53.853897Z",
          "iopub.execute_input": "2024-12-08T07:55:53.854195Z",
          "iopub.status.idle": "2024-12-08T07:58:26.244799Z",
          "shell.execute_reply.started": "2024-12-08T07:55:53.854166Z",
          "shell.execute_reply": "2024-12-08T07:58:26.243767Z"
        },
        "id": "O41PhzAKmX1O",
        "outputId": "3657a0e3-20fc-4db9-888b-0a34eef8eb8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it-bnb-4bit and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_and_tokenize(batch):\n",
        "    sep_token = tokenizer.sep_token if tokenizer.sep_token is not None else \"</s>\"\n",
        "    combined = [\n",
        "        f\"{p} {sep_token} {ra} {sep_token} {rb}\"\n",
        "        for p, ra, rb in zip(batch[\"prompt\"], batch[\"response_a\"], batch[\"response_b\"])\n",
        "    ]\n",
        "    tokenized = tokenizer(\n",
        "        combined,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=config.max_length,\n",
        "    )\n",
        "    # Convert winner from \"model_a\" / \"model_b\" to 0 / 1\n",
        "    labels = [0 if w == \"model_a\" else 1 for w in batch[\"winner\"]]\n",
        "    tokenized[\"labels\"] = labels\n",
        "    return tokenized\n",
        "\n",
        "# Load full dataset\n",
        "train_df = pd.read_parquet(config.train_parquet)\n",
        "\n",
        "# Select the last 10% of the rows\n",
        "data_length = len(train_df)\n",
        "fraction = 1\n",
        "start_idx = int(data_length * (1 - fraction))\n",
        "subset_df = train_df.iloc[start_idx:].reset_index(drop=True)\n",
        "\n",
        "hf_dataset = Dataset.from_pandas(subset_df)\n",
        "\n",
        "# Apply tokenization and pairing\n",
        "tokenized_dataset = hf_dataset.map(preprocess_and_tokenize, batched=True)\n",
        "\n",
        "# Remove unnecessary columns\n",
        "tokenized_dataset = tokenized_dataset.remove_columns([\"prompt\", \"response_a\", \"response_b\", \"winner\"])\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_dataset.set_format(\"torch\")\n",
        "\n",
        "# Train/Test split\n",
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = split_dataset[\"train\"]\n",
        "eval_dataset = split_dataset[\"test\"]\n"
      ],
      "metadata": {
        "_uuid": "9452ae04-94e3-44f9-b81d-5dbad3a37104",
        "_cell_guid": "76babcb8-107d-4741-9d39-6ce96a167028",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T08:01:02.59569Z",
          "iopub.execute_input": "2024-12-08T08:01:02.596057Z",
          "iopub.status.idle": "2024-12-08T08:01:06.180637Z",
          "shell.execute_reply.started": "2024-12-08T08:01:02.596023Z",
          "shell.execute_reply": "2024-12-08T08:01:06.179926Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "M8jiwPB9mX1O",
        "outputId": "80ae01e3-edcf-46db-97b3-bfef2d916252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a612a945c482487d9052cdf7703af8fe",
            "b3b61e96d8a544ea97b4ccd50eaf1cb3",
            "3dd25d8aa94a42e9bce729565b69586d",
            "25a8ac93fcc84463a701094802de2421",
            "1b8ab69b6a9447599432ffdd041f9ece",
            "dfbbb379c5104807994de4d039de0b7a",
            "ca6c834d83b64c23a0cd038e6ccba46d",
            "55a400f11c9f4f508b7e0e3407d110ee",
            "535e83ed058f493b9090792e174e9cdc",
            "e153a3b809f545ccb31ab0670a24b5b8",
            "f9316725a85644faa47259a3ae4ab03d"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/48439 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a612a945c482487d9052cdf7703af8fe"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
        "    preds = eval_preds.predictions\n",
        "    labels = eval_preds.label_ids\n",
        "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n",
        "    loss = log_loss(y_true=labels, y_pred=probs)\n",
        "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n",
        "    return {\"acc\": acc, \"log_loss\": loss}"
      ],
      "metadata": {
        "_uuid": "f7b8470d-63f3-4141-8063-d5152dea82f2",
        "_cell_guid": "71d28a16-3ec2-414c-87fb-2b236b80e19c",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-08T07:58:33.075541Z",
          "iopub.execute_input": "2024-12-08T07:58:33.076257Z",
          "iopub.status.idle": "2024-12-08T07:58:33.081063Z",
          "shell.execute_reply.started": "2024-12-08T07:58:33.076212Z",
          "shell.execute_reply": "2024-12-08T07:58:33.080141Z"
        },
        "id": "O362g3_PmX1O"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "_uuid": "f24cbaf1-1de3-4ab5-9a94-c49688cf22c8",
        "_cell_guid": "2f6c3334-d4b1-4ad9-90cb-43e44434f101",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-12-08T08:01:10.963089Z",
          "iopub.execute_input": "2024-12-08T08:01:10.963943Z",
          "iopub.status.idle": "2024-12-08T08:01:10.974341Z",
          "shell.execute_reply.started": "2024-12-08T08:01:10.963904Z",
          "shell.execute_reply": "2024-12-08T08:01:10.973448Z"
        },
        "id": "j7te2NtXmX1O",
        "outputId": "b688ba4b-bbcd-463a-e662-bcb65b45cd06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-8df10da392e8>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "_uuid": "7cf263de-40c0-4445-a2a1-b87e998842d7",
        "_cell_guid": "31aa5a84-d55e-48a5-9a4e-d996df629a96",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T08:01:15.851129Z",
          "iopub.execute_input": "2024-12-08T08:01:15.851495Z",
          "iopub.status.idle": "2024-12-08T09:48:57.248557Z",
          "shell.execute_reply.started": "2024-12-08T08:01:15.851463Z",
          "shell.execute_reply": "2024-12-08T09:48:57.247661Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Gh0W3Dq6mX1O",
        "outputId": "1a4947f4-477e-4e8a-b76d-8175b8c39e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshivzzzzzz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241209_114738-1hpp2sn2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shivzzzzzz/huggingface/runs/1hpp2sn2' target=\"_blank\">output</a></strong> to <a href='https://wandb.ai/shivzzzzzz/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/shivzzzzzz/huggingface' target=\"_blank\">https://wandb.ai/shivzzzzzz/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/shivzzzzzz/huggingface/runs/1hpp2sn2' target=\"_blank\">https://wandb.ai/shivzzzzzz/huggingface/runs/1hpp2sn2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='111' max='5449' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 111/5449 51:09 < 41:45:19, 0.04 it/s, Epoch 0.02/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.model.save_pretrained(config.output_dir)"
      ],
      "metadata": {
        "_uuid": "4f065904-b613-4f44-b1cd-82749da2061b",
        "_cell_guid": "8a9889ea-ac41-4137-a7d9-5ad6e06ca644",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-08T09:48:57.249992Z",
          "iopub.execute_input": "2024-12-08T09:48:57.250266Z",
          "iopub.status.idle": "2024-12-08T09:48:57.702916Z",
          "shell.execute_reply.started": "2024-12-08T09:48:57.250239Z",
          "shell.execute_reply": "2024-12-08T09:48:57.701964Z"
        },
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "eJk5IYysmX1O"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}